{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A module that makes downloading and using datasets from the Gene Expression Omnibus (GEO) easy.\n",
    "\n",
    "Author: Joshua Blanchard, jeblanchard@berkeley.edu\n",
    "\n",
    "Currently has limited functionality.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re as re\n",
    "import xmltodict\n",
    "import ftplib\n",
    "import tarfile\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__base_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__hidden_path = \".aidp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(__base_path):\n",
    "    os.mkdir(__base_path)\n",
    "    \n",
    "if not os.path.exists(__hidden_path):\n",
    "    os.mkdir(__hidden_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __family_path(GSE_family):\n",
    "    \n",
    "    \"\"\"Exists to build paths to the family's directory.\n",
    "    \n",
    "    I downloaded the files using the download() function in conjuction with the extract() function.\"\"\"\n",
    "        \n",
    "    return os.path.join(__base_path, GSE_family + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean(file_path):\n",
    "    \n",
    "    \"\"\"Cleans a given .txt file.\n",
    "    \n",
    "    Returns a dictionary:\n",
    "    \n",
    "    \"site\": first column\n",
    "    \"measurement\": second column\n",
    "    \"bad_rows\": list of all the invalid rows\"\"\"\n",
    "\n",
    "    valid_rows = []\n",
    "    not_valid_rows = []\n",
    "    file = open(file_path, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "#         checks for only the first two columns\n",
    "        line_match = re.match(r\"\\S+\\t\\S+\", line)\n",
    "        if line_match:\n",
    "            valid_rows.append(line_match.group(0))\n",
    "        else:\n",
    "            not_valid_rows.append(line)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "#     now let's split our valid_rows list into two lists, one for each column\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    for row in valid_rows:\n",
    "        row_match = re.match(r\"(\\S+)\\t(\\S+)\", row)\n",
    "        col_1.append(row_match.group(1))\n",
    "        col_2.append(row_match.group(2))\n",
    "        \n",
    "    return {\"col_1\":col_1, \"col_2\":col_2, \"bad_rows\":not_valid_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_file(file_directory):\n",
    "#     clean data file\n",
    "#     convert to a dataframe object and return\n",
    "\n",
    "    \"\"\"Given a file name will output a corresponding pandas.DataFrame object.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        clean_dict = __clean(file_directory)\n",
    "    except PermissionError:\n",
    "        print(\"You likely inputted the path of a directory, not a file.\")\n",
    "    \n",
    "#     return pd.DataFrame({\"site\": clean_dict[\"col_1\"], \"measurement\": clean_dict[\"col_2\"]})\n",
    "    return pd.DataFrame(data= clean_dict[\"col_2\"], index= clean_dict[\"col_1\"], columns= [\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict(GSE_family):\n",
    "    \n",
    "    \"\"\"*** DEPRECATED *** \n",
    "    \n",
    "    Given a family ID, will output a dictionary. Keys will be the sample IDs, values will be the corresponding\n",
    "    pandas.DataFrame object.\"\"\"\n",
    "\n",
    "#     let's check if we already have this dictionary saved\n",
    "    if not os.path.exists(\"./\" + __hidden_path):\n",
    "        os.mkdir(__hidden_path)\n",
    "    \n",
    "    dict_path = __hidden_path + \"/\" + GSE_family + \"_dict\"    \n",
    "    if not os.path.exists(dict_path):\n",
    "    \n",
    "        family_directory = __family_path(GSE_family)\n",
    "        total_list = os.listdir(family_directory)\n",
    "        valid_files = []\n",
    "\n",
    "        for file_name in total_list:\n",
    "            match = re.match(r\"GSM\", file_name)\n",
    "            if match:\n",
    "                valid_files.append(file_name)\n",
    "\n",
    "        family_dict = {}\n",
    "        for file_name in valid_files:\n",
    "            file_df = __load_file(os.path.join(family_directory, file_name))\n",
    "            sample_id = re.match(r\"GSM\\d+\", file_name).group(0)\n",
    "            family_dict[sample_id] = file_df\n",
    "            \n",
    "        dict_file = open(dict_path, 'wb')\n",
    "        pickle.dump(family_dict, dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "    else:\n",
    "        dict_file = open(dict_path, 'rb')\n",
    "        family_dict = pickle.load(dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "        \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_helper(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns a tuple containing the start line for reading (0) and the number of rows to read (1).\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_path, mode= 'r', errors= 'replace')\n",
    "    \n",
    "    line_num = 0\n",
    "    if use == \"series()\":\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            \n",
    "            if \"!series_matrix_table_begin\" in line:\n",
    "                start_row = line_num\n",
    "            elif \"!series_matrix_table_end\" in line:\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "        \n",
    "    else:\n",
    "                \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if \"!Sample_title\" in line:\n",
    "                start_row = line_num\n",
    "            elif \"!series_matrix_table_begin\" in line:\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "\n",
    "    num_rows = end_row - start_row - 1\n",
    "        \n",
    "    return start_row, num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_to_df(file_path, use= \"series()\", GSE= \"\"):\n",
    "    \n",
    "    \"\"\"Returns the pandas.dataframe corresponding to the series_matrix file.\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "\n",
    "    if use == \"series()\":\n",
    "        \n",
    "        series_path = os.path.join(__hidden_path + \"/\" + GSE + \"/\" + \"series_df\")\n",
    "    \n",
    "        if os.path.exists(series_path):\n",
    "\n",
    "            df_file = open(series_path, \"rb\")\n",
    "            df = pickle.load(df_file)\n",
    "            df_file.close()\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            start_row, num_rows = __matrix_helper(file_path, use)\n",
    "            df = pd.read_csv(file_path, header= start_row, sep= \"\\t\", low_memory= False, nrows= num_rows)\n",
    "            df.set_index(\"ID_REF\", inplace= True)\n",
    "            \n",
    "            GSE_dir = os.path.join(__hidden_path + \"/\" + GSE)\n",
    "            if not os.path.exists(GSE_dir):\n",
    "                os.mkdir(GSE_dir)\n",
    "            \n",
    "            df_file = open(series_path, 'wb')\n",
    "            pickle.dump(df, df_file)\n",
    "            df_file.close()\n",
    "            \n",
    "    elif use == \"info()\":\n",
    "        \n",
    "        info_path = os.path.join(__hidden_path + \"/\" + GSE + \"/\" + \"info_df\")\n",
    "    \n",
    "        if os.path.exists(info_path):\n",
    "\n",
    "            info_df_file = open(info_path, \"rb\")\n",
    "            df = pickle.load(info_df_file)\n",
    "            info_df_file.close()\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            start_row, num_rows = __matrix_helper(file_path, use)\n",
    "            df = pd.read_csv(file_path, header= start_row, sep= \"\\t\", low_memory= False, nrows= num_rows)\n",
    "            \n",
    "            df.set_index(\"!Sample_geo_accession\", inplace= True)\n",
    "            df = df.loc[\"!Sample_characteristics_ch1\"]\n",
    "            \n",
    "            GSE_dir = os.path.join(__hidden_path + \"/\" + GSE)\n",
    "            if not os.path.exists(GSE_dir):\n",
    "                os.mkdir(GSE_dir)\n",
    "            \n",
    "            df_file = open(info_path, 'wb')\n",
    "            pickle.dump(df, df_file)\n",
    "            df_file.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(GSE_family, sample_id, info= \"age\"):\n",
    "    \n",
    "    \"\"\"Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": the unit of the outputted age will always be years.\n",
    "    \"brca1\": the BRCA1 mutation status for GSE57285\n",
    "    \"arthritis\": the arthritis status for GSE42861\n",
    "    \"crohns\": the Crohn's disease status for GSE32148\"\"\"\n",
    "#     create dataframe of sample characteristics portion of the series_matrix file\n",
    "# read desired info from this dataframe. will have to use regex to find the right information\n",
    "# set up some sort of persistance of this dataframe for faster retrieval of information\n",
    "\n",
    "#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\n",
    "\n",
    "    info_df = __matrix_to_df(\"./\" + __base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\", use= \"info()\", GSE= GSE_family)    \n",
    "    info_series = info_df.loc[:, sample_id]\n",
    "        \n",
    "    \n",
    "    if info == \"age\":\n",
    "        \n",
    "        for row in info_series:\n",
    "            match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "            if match_age:\n",
    "        #         let's grab the age\n",
    "                match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "                if match_age_dig:\n",
    "                    age_float = float(match_age_dig.group())\n",
    "    #             to account for \"newborn\" instead of an actual number\n",
    "                else:\n",
    "                    age_float = 0.0\n",
    "\n",
    "        #         now let's find the unit of age\n",
    "                match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "                match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "                match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "                match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "\n",
    "        #         we always return the age in units of years\n",
    "                if match_years:\n",
    "                    return age_float\n",
    "                elif match_months:\n",
    "                    return age_float / 12\n",
    "                elif match_days:\n",
    "                    return age_float / 365\n",
    "                elif match_hours:\n",
    "                    return age_float / 8760\n",
    "                else:\n",
    "        #             if no unit is given we'll default to years\n",
    "                    return age_float\n",
    "        \n",
    "    elif info == \"brca1\":\n",
    "            \n",
    "        for row in info_series:\n",
    "            match_status = re.search(r\"brca1 mutation status\", row)\n",
    "            if match_status:\n",
    "        #         let's grab the brca1 status\n",
    "                match_status_dig = re.search(r\"(brca1 mutation status: )(\\d)\", row)\n",
    "                if match_status_dig:\n",
    "                    status_int = int(match_status_dig.group(2))\n",
    "\n",
    "                    return status_int\n",
    "    \n",
    "    elif info == \"arthritis\":\n",
    "        \n",
    "        for row in info_series:\n",
    "            match_arth = re.search(r\"disease state\", row)\n",
    "            if match_arth:\n",
    "        #         let's grab the arthritis status\n",
    "                match_arth_status = re.search(r\"(disease state: )(\\S+)\", row)\n",
    "                if match_arth_status.group(2) == \"rheumatoid\":\n",
    "                    return \"rheumatoid arthritis\"\n",
    "                else:\n",
    "                    return \"normal\"\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        for row in info_series:\n",
    "            match_crohns = re.search(r\"disease state\", row)\n",
    "            if match_crohns:\n",
    "        #         let's grab the Crohn's status\n",
    "                match_crohns_status = re.search(r\"(disease state: )(\\S+)\", row)\n",
    "                return match_crohns_status.group(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ID_to_int(GSE_ID):\n",
    "    \n",
    "    \"\"\"Given some GSE ID will return the corresponding integer as an int.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    __ID_to_int(\"GSE41037\") will return 41037.\"\"\"\n",
    "    \n",
    "    match = re.search(r\"\\d+\", GSE_ID)\n",
    "    \n",
    "    if not match:\n",
    "        print(GSE_ID)\n",
    "    \n",
    "    return int(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sub_directory(GSE_ID):\n",
    "    \n",
    "    \"\"\"Given a GSE ID will return the corresponding sub-directory.\"\"\"\n",
    "    \n",
    "    gse_int = __ID_to_int(GSE_ID)\n",
    "    \n",
    "    if gse_int <= 171:\n",
    "        ret_str = \"GSE\" + str(gse_int) + \"nnn\"\n",
    "    else:\n",
    "        first_3_dig = int(str(gse_int)[0:3])\n",
    "        if first_3_dig <= 171:\n",
    "            ret_str = \"GSE\" + str(first_3_dig) + \"nnn\"\n",
    "        else:\n",
    "            first_2_dig_str = str(gse_int)[0:2]\n",
    "            ret_str = \"GSE\" + first_2_dig_str + \"nnn\"\n",
    "            \n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(GSE_family_list, file_type= \"miniml\"):\n",
    "    \n",
    "    \"\"\"Will download family .tgz files to the following directory: \"./data/\"\n",
    "    \n",
    "    Possible values for file_type: \"miniml\", \"series_matrix\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(GSE_family_list) == str):\n",
    "        GSE_family_list = [GSE_family_list]\n",
    "\n",
    "    url = \"ftp.ncbi.nlm.nih.gov\"\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login()\n",
    "    \n",
    "    if not os.path.exists(__base_path):\n",
    "        os.mkdir(__base_path)\n",
    "    \n",
    "    for GSE_family in GSE_family_list:\n",
    "        \n",
    "        if file_type == \"miniml\":\n",
    "        \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/miniml/\")\n",
    "            filename = GSE_family + \"_family.xml.tgz\"\n",
    "            \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family)):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/matrix/\")\n",
    "            filename = GSE_family + \"_series_matrix.txt.gz\"\n",
    "        \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\")):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "\n",
    "    ftp.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __check_beta(series_df):\n",
    "    \n",
    "    \"\"\"Returns True if Beta values are recorded, returns False if M values are recorded.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series(GSE):\n",
    "    \n",
    "    \"\"\"Returns a pandas.DataFrame representative of the series' data.\"\"\"\n",
    "    \n",
    "#     download(GSE, file_type= \"series_matrix\")\n",
    "#     __extract()\n",
    "    \n",
    "    file_path = os.path.join(__base_path, GSE, GSE + \"_series_matrix.txt\")\n",
    "    \n",
    "    return __matrix_to_df(file_path, GSE= GSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_path(GSE_family):\n",
    "    \n",
    "    \"\"\"Exists to build a path to the family's .xml.\n",
    "    \n",
    "    I downloaded these families using the download() function in conjuction with the extract() function.\"\"\"\n",
    "    \n",
    "    return os.path.join(__base_path, GSE_family + \"/\" + GSE_family + \"_family.xml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_to_dict(xml_path):\n",
    "    \n",
    "    \"\"\"Exists to convert a .xml file at xml_path to a dictionary.\"\"\"\n",
    "    \n",
    "    family_file = open(xml_path,'r+b')\n",
    "    family_dict = xmltodict.parse(family_file)\n",
    "    family_file.close()\n",
    "    \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __dict_index(GSE_family, sample_id):\n",
    "    \n",
    "    \"\"\"Gives the index of where in the dictionary the sample's information is.\"\"\"\n",
    "    \n",
    "    return __sample_indices(GSE_family)[sample_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sample_indices(GSE_family):\n",
    "    \n",
    "    \"\"\"Exists to return the indices of each sample's information within the associated family dictionary. Returns a dictionary\n",
    "    with keys equal to the sample ID (\"GSM***\") and values equal to the index of that sample's information within the family\n",
    "    dictionary.\"\"\"\n",
    "    \n",
    "    family_dir = __family_path(GSE_family)\n",
    "    file_list = os.listdir(family_dir)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for file_name in file_list:\n",
    "        sample_match = re.match(r\"GSM\", file_name)\n",
    "        if sample_match:\n",
    "            filtered_list.append(file_name)\n",
    "            \n",
    "    for i in np.arange(len(filtered_list)):\n",
    "        filtered_list[i] = re.match(r\"GSM\\d+\", filtered_list[i]).group(0)\n",
    "        \n",
    "    index_dict = {}\n",
    "    index = 0\n",
    "\n",
    "    for sample_id in filtered_list:\n",
    "        index_dict[sample_id] = index\n",
    "        index += 1\n",
    "        \n",
    "    return index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __extract():\n",
    "    \n",
    "    \"\"\"Will extract files from all downloaded family .tgz files to a respective directory: ./data/GSE***/\n",
    "    \n",
    "    This will also delete the .tgz and .gz files.\"\"\"\n",
    "\n",
    "    file_list = os.listdir(__base_path)\n",
    "    tgz_list = []\n",
    "    gz_list = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match_tgz = re.search(r\"\\.tgz\", filename)\n",
    "        match_gz = re.search(r\"\\.gz\", filename)\n",
    "        \n",
    "        if match_tgz:\n",
    "            tgz_list.append(filename)\n",
    "        elif match_gz:\n",
    "            gz_list.append(filename)\n",
    "                \n",
    "    flag = False\n",
    "    \n",
    "    for filename in tgz_list:\n",
    "        full_path = __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        file = tarfile.open(full_path)\n",
    "        \n",
    "        try:\n",
    "            out_path = \"./\" + __base_path + \"/\" + family_id\n",
    "            file.extractall(out_path)\n",
    "        except:\n",
    "#             let's end the content extraction of the file. will fix later.\n",
    "            file.close()\n",
    "    \n",
    "            flag = True\n",
    "            print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "            \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "            \n",
    "    \n",
    "    for filename in gz_list:\n",
    "        full_path = \"./\" + __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        compressed_file = open(full_path, 'rb')\n",
    "        compressed_file_contents = compressed_file.read()\n",
    "        compressed_file.close()\n",
    "                \n",
    "        split_compressed_bytes = compressed_file_contents.split()\n",
    "        contents_str = ''\n",
    "        \n",
    "        \n",
    "        for compressed_bytes in split_compressed_bytes:\n",
    "            contents_bytes = gzip.decompress(compressed_bytes)\n",
    "            contents_str.append(contents_bytes.decode(errors= \"replace\"))\n",
    "        \n",
    "        family_dir = os.path.join(__base_path, family_id)\n",
    "        if not os.path.exists(family_dir):\n",
    "            os.mkdir(family_dir)\n",
    "        \n",
    "        out_path = \"./\" + __base_path + \"/\" + family_id + \"/\" + family_id + \"_series_matrix.txt\"\n",
    "\n",
    "        file = open(out_path, mode= 'w', encoding= \"utf-8\")\n",
    "        \n",
    "        file.write(contents_str)\n",
    "        file.close()\n",
    "    \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
